{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##### Jupyter Notebook, Step 4 - Build Model\n",
    "- Implement your final model\n",
    "- (Optionally) use the entire data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "# from sklearn.feature_selection import SelectPercentile, SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import (precision_score, \n",
    "                             accuracy_score, \n",
    "                             roc_auc_score, \n",
    "                             roc_curve, \n",
    "                             precision_recall_curve, \n",
    "                             recall_score\n",
    "#                              make_scorer,\n",
    "#                              auc,\n",
    "#                              classification_report,\n",
    "#                              confusion_matrix\n",
    "                            )\n",
    "# !conda install psycopg2 --yes\n",
    "# import psycopg2 as pg2\n",
    "# from psycopg2.extras import RealDictCursor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw all the data for just our 20 features\n",
    "\n",
    "# run the models above a certain threshold on these, w/ a held-out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import UCI madelon data and set the nan column to labels\n",
    "\n",
    "def import_and_labels(data, labels):\n",
    "    \n",
    "    data = data\n",
    "    labels = labels\n",
    "    madelon_train = pd.read_csv(data, delimiter=' ', header=None)\n",
    "    madelon_labels = pd.read_csv(labels, delimiter=' ', header=None)\n",
    "    madelon_train[500] = madelon_labels\n",
    "\n",
    "    return madelon_train\n",
    "\n",
    "madelon_train = import_and_labels('madelon_train.data.csv','madelon_train.labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCIsample_list = [28,48,64,105,128,153,241,281,318,336,338,378,433,442,451,453,455,472,475,493,500]\n",
    "DBsample_list = ['feat_257','feat_269','feat_308','feat_315',\\\n",
    "                 'feat_336','feat_341','feat_395','feat_504','feat_526','feat_639','feat_681',\\\n",
    "                 'feat_701','feat_724','feat_736','feat_769','feat_808','feat_829','feat_867','feat_920',\\\n",
    "                 'feat_956','target']\n",
    "\n",
    "def drop_noise(df, signal_list):\n",
    "    temp_df = df\n",
    "    for column in temp_df.columns:\n",
    "        if column not in signal_list:\n",
    "            temp_df.drop(column, axis=1, inplace=True)\n",
    "    return temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UCIfull_clean = drop_noise(madelon_train, UCIsample_list)\n",
    "UCIfull_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(UCIfull_clean, open('UCIfull_clean', \"wb\" ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def con_cur_to_class_db():\n",
    "    con = pg2.connect(host='34.211.227.227',\n",
    "                  dbname='postgres',\n",
    "                  user='postgres')\n",
    "    cur = con.cursor(cursor_factory=RealDictCursor)\n",
    "    return con, cur\n",
    "\n",
    "def draw_sample():\n",
    "    con, cur = con_cur_to_class_db()\n",
    "    cur.execute('SELECT feat_257,feat_269,feat_308,feat_315,feat_336,feat_341,feat_395,feat_504,feat_526,feat_639,feat_681,feat_701,feat_724,feat_736,feat_769,feat_808,feat_829,feat_867,feat_920,feat_956,target FROM madelon;')\n",
    "    mad_db = cur.fetchall()\n",
    "    con.close()\n",
    "    return pd.DataFrame(mad_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBfull_clean = draw_sample()\n",
    "pickle.dump(DBfull_clean, open('DBfull_clean', \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBfull_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DBfull_clean = pickle.load( open( \"DBfull_clean\", \"rb\" ) )\n",
    "\n",
    "# drop the seemingly unneeded ID column\n",
    "# DBfull_clean.drop('_id', axis=1, inplace=True)\n",
    "DBfull_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define my controlling function and pipelines to gridsearch\n",
    "\n",
    "DBfull_clean = pickle.load( open( \"DBfull_clean\", \"rb\" ) )\n",
    "UCIfull_clean = pickle.load( open( \"UCIfull_clean\", \"rb\" ) )\n",
    "\n",
    "def score_pipelines(sample_list, model_zip):\n",
    "    results = []\n",
    "    for sample in sample_list:\n",
    "        y = sample.iloc[:,-1]\n",
    "        X = sample.iloc[:,0:-1]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size=0.25, stratify=y)\n",
    "        for model_name, model in tqdm(model_zip):\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            results.append({\n",
    "                    'sample': sample.name,\n",
    "                    'name':'{}'.format(model_name),\n",
    "                    'model': model,\n",
    "                    'best_params': model.best_params_,\n",
    "                    'train_accuracy': model.score(X_train, y_train),\n",
    "                    'test_accuracy': model.score(X_test, y_test),\n",
    "                    'recall': recall,\n",
    "                    'precision': precision,\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "knn = Pipeline([\n",
    "    ('scaling', StandardScaler()), \n",
    "#     ('scaling', StandardScaler(with_mean=False)), \n",
    "    ('pca', PCA(n_components=5)),\n",
    "    ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "svc = Pipeline([\n",
    "    ('scaling', StandardScaler()), \n",
    "#     ('scaling', StandardScaler(with_mean=False)),     \n",
    "    ('pca', PCA(n_components=5)),\n",
    "    ('classifier', SVC())])\n",
    "\n",
    "bag = Pipeline([\n",
    "    ('scaling', StandardScaler()), \n",
    "#     ('scaling', StandardScaler(with_mean=False)),     \n",
    "    ('pca', PCA(n_components=5)),\n",
    "    ('clf', BaggingClassifier(DecisionTreeClassifier(random_state=42), max_samples=.8, random_state=42))])\n",
    "\n",
    "rfc = Pipeline([\n",
    "    ('scaling', StandardScaler()), \n",
    "#     ('scaling', StandardScaler(with_mean=False)),     \n",
    "    ('pca', PCA(n_components=5)),\n",
    "    ('clf',RandomForestClassifier(random_state=42))])\n",
    "\n",
    "etc = Pipeline([\n",
    "    ('scaling', StandardScaler()), \n",
    "#     ('scaling', StandardScaler(with_mean=False)),     \n",
    "    ('pca', PCA(n_components=5)),\n",
    "    ('clf',ExtraTreesClassifier(random_state=42))])\n",
    "\n",
    "knn_params = {\n",
    "              'classifier__weights':['distance'],\n",
    "              'classifier__n_neighbors':np.arange(3,13,2)}\n",
    "\n",
    "svc_params = {\n",
    "               'classifier__gamma':np.logspace(-3,3,7), \n",
    "               'classifier__C':np.logspace(-3,3,7),\n",
    "               'classifier__kernel':['rbf']}\n",
    "\n",
    "bag_params = {\n",
    "    'clf__base_estimator': [DecisionTreeClassifier(max_depth=md, random_state=42) for md in [5,7,10,None]],\n",
    "    'clf__n_estimators':[10,50,100]}\n",
    "\n",
    "rfc_params = {\n",
    "    'clf__n_estimators':[10,50,100,200],\n",
    "    'clf__max_features':['auto','log2']}\n",
    "\n",
    "etc_params = {\n",
    "    'clf__bootstrap':[True, False],\n",
    "    'clf__n_estimators':[10,50,100,200]}\n",
    "\n",
    "bag_gs = GridSearchCV(bag, bag_params, cv=5, n_jobs=-1, verbose=1)\n",
    "rfc_gs = GridSearchCV(rfc, rfc_params, cv=5, n_jobs=-1, verbose=1)\n",
    "etc_gs = GridSearchCV(etc, etc_params, cv=5, n_jobs=-1, verbose=1)\n",
    "knn_gs = GridSearchCV(knn, knn_params, cv=5, n_jobs=-1, verbose=1)\n",
    "svc_gs = GridSearchCV(svc, svc_params, cv=5, n_jobs=-1, verbose=1)\n",
    "\n",
    "UCIfull_clean.name = 'UCIfull_clean'\n",
    "DBfull_clean.name = 'DBfull_clean' \n",
    "\n",
    "# drop pipes that did poorly in gridsearching after tuning: logr, dct, \n",
    "pipe_names = ['knn_gs', 'svc_gs', 'bag_gs', 'rfc_gs', 'etc_gs']\n",
    "pipe_list = [knn_gs, svc_gs, bag_gs, rfc_gs, etc_gs]\n",
    "model_zip = list(zip(pipe_names, pipe_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/feature_selection/base.py:80: UserWarning: No features were selected: either the data is too noisy or the selection test too strict.\n",
      "  UserWarning)\n",
      "\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/opt/conda/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/opt/conda/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f79def11ed0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/opt/conda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f79def11ed0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/opt/conda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 11, 1, 10, 26, 734374, tzinfo=tzlocal()), 'msg_id': 'A0341C46063B4393B8F8B29085A5CB59', 'msg_type': 'execute_request', 'session': 'B7857C7A06174F88859E10F31B92B67D', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'A0341C46063B4393B8F8B29085A5CB59', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'B7857C7A06174F88859E10F31B92B67D']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 11, 1, 10, 26, 734374, tzinfo=tzlocal()), 'msg_id': 'A0341C46063B4393B8F8B29085A5CB59', 'msg_type': 'execute_request', 'session': 'B7857C7A06174F88859E10F31B92B67D', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'A0341C46063B4393B8F8B29085A5CB59', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'B7857C7A06174F88859E10F31B92B67D'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 11, 1, 10, 26, 734374, tzinfo=tzlocal()), 'msg_id': 'A0341C46063B4393B8F8B29085A5CB59', 'msg_type': 'execute_request', 'session': 'B7857C7A06174F88859E10F31B92B67D', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'A0341C46063B4393B8F8B29085A5CB59', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\", store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-9-83908fb7087f>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f79a0993898, executi..._before_exec=None error_in_exec=None result=None>)\n   2845 \n   2846         try:\n   2847             for i, node in enumerate(to_run_exec):\n   2848                 mod = ast.Module([node])\n   2849                 code = compiler(mod, cell_name, \"exec\")\n-> 2850                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f79a0ae6ae0, file \"<ipython-input-9-83908fb7087f>\", line 2>\n        result = <ExecutionResult object at 7f79a0993898, executi..._before_exec=None error_in_exec=None result=None>\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f79a0ae6ae0, file \"<ipython-input-9-83908fb7087f>\", line 2>, result=<ExecutionResult object at 7f79a0993898, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f79a0ae6ae0, file \"<ipython-input-9-83908fb7087f>\", line 2>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'DBfull_clean':         feat_257  feat_269  feat_308  feat_315  ...0 -0.559682       1  \n\n[200000 rows x 21 columns], 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport numpy as np\\nimport se...ictCursor\\nfrom sklearn.linear_model import Linear', 'import pandas as pd\\nimport numpy as np\\nimport se...DictCursor\\nfrom sklearn.linear_model import Lasso', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', 'import pandas as pd\\nimport numpy as np\\nimport se... sklearn.feature_selection import SelectFromModel', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', \"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\"], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'DBfull_clean':         feat_257  feat_269  feat_308  feat_315  ...0 -0.559682       1  \n\n[200000 rows x 21 columns], 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport numpy as np\\nimport se...ictCursor\\nfrom sklearn.linear_model import Linear', 'import pandas as pd\\nimport numpy as np\\nimport se...DictCursor\\nfrom sklearn.linear_model import Lasso', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', 'import pandas as pd\\nimport numpy as np\\nimport se... sklearn.feature_selection import SelectFromModel', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', \"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\"], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/jovyan/work/project_3/<ipython-input-9-83908fb7087f> in <module>()\n      1 \n----> 2 \n      3 \n      4 \n      5 sample_list = [UCIfull_clean]\n      6 results = score_pipelines(sample_list, model_zip)\n      7 display(results.sort_values('test_accuracy', ascending=False))\n      8 \n      9 \n     10 \n\n...........................................................................\n/home/jovyan/work/project_3/<ipython-input-8-d78be5dfc6fc> in score_pipelines(sample_list=[      28   48   64   105  128  153  241  281  31...2  487  560  449    1  \n\n[2000 rows x 21 columns]], model_zip=[('knn_gs', GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1)), ('svc_gs', GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1)), ('bag_gs', GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1)), ('rfc_gs', GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1)), ('etc_gs', GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1))])\n      8     for sample in sample_list:\n      9         y = sample.iloc[:,-1]\n     10         X = sample.iloc[:,0:-1]\n     11         X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size=0.25, stratify=y)\n     12         for model_name, model in tqdm(model_zip):\n---> 13             model.fit(X_train, y_train)\n     14             y_pred = model.predict(X_test)\n     15             recall = recall_score(y_test, y_pred)\n     16             precision = precision_score(y_test, y_pred)\n     17             results.append({\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1), X=      28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns], y=1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64, groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...rain_score=True,\n       scoring=None, verbose=1)>\n        X =       28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns]\n        y = 1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64\n        groups = None\n        self.param_grid = {'classifier__n_neighbors': array([ 3,  5,  7,  9, 11]), 'classifier__weights': ['distance']}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1), X=      28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns], y=1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Nov 11 01:10:26 2017\nPID: 170                                Python 3.6.2: /opt/conda/bin/python\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaling', StandardScaler(copy=...ighbors=3, p=2,\n           weights='distance'))]),       28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns], 1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64, <function _passthrough_scorer>, array([ 283,  286,  287, ..., 1497, 1498, 1499]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...99, 300, 301, 307, 308, 311, 315, 316, 317, 318]), 1, {'classifier__n_neighbors': 3, 'classifier__weights': 'distance'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('scaling', StandardScaler(copy=...ighbors=3, p=2,\n           weights='distance'))]),       28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns], 1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64, <function _passthrough_scorer>, array([ 283,  286,  287, ..., 1497, 1498, 1499]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...99, 300, 301, 307, 308, 311, 315, 316, 317, 318]), 1, {'classifier__n_neighbors': 3, 'classifier__weights': 'distance'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaling', StandardScaler(copy=...ighbors=3, p=2,\n           weights='distance'))]), X=      28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns], y=1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64, scorer=<function _passthrough_scorer>, train=array([ 283,  286,  287, ..., 1497, 1498, 1499]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...99, 300, 301, 307, 308, 311, 315, 316, 317, 318]), verbose=1, parameters={'classifier__n_neighbors': 3, 'classifier__weights': 'distance'}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...ghbors=3, p=2,\n           weights='distance'))])>\n        X_train =       28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1200 rows x 20 columns]\n        y_train = 569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaling', StandardScaler(copy=...ighbors=3, p=2,\n           weights='distance'))]), X=      28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1200 rows x 20 columns], y=569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64, **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method SupervisedIntegerMixin.fit of KNei...neighbors=3, p=2,\n           weights='distance')>\n        Xt = array([], shape=(1200, 0), dtype=float64)\n        y = 569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/neighbors/base.py in fit(self=KNeighborsClassifier(algorithm='auto', leaf_size..._neighbors=3, p=2,\n           weights='distance'), X=array([], shape=(1200, 0), dtype=float64), y=569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64)\n    756         y : {array-like, sparse matrix}\n    757             Target values of shape = [n_samples] or [n_samples, n_outputs]\n    758 \n    759         \"\"\"\n    760         if not isinstance(X, (KDTree, BallTree)):\n--> 761             X, y = check_X_y(X, y, \"csr\", multi_output=True)\n        X = array([], shape=(1200, 0), dtype=float64)\n        y = 569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64\n    762 \n    763         if y.ndim == 1 or y.ndim == 2 and y.shape[1] == 1:\n    764             if y.ndim != 1:\n    765                 warnings.warn(\"A column-vector y was passed when a 1d array \"\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py in check_X_y(X=array([], shape=(1200, 0), dtype=float64), y=569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64, accept_sparse='csr', dtype='numeric', order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=True, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    516     y_converted : object\n    517         The converted and validated y.\n    518     \"\"\"\n    519     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n    520                     ensure_2d, allow_nd, ensure_min_samples,\n--> 521                     ensure_min_features, warn_on_dtype, estimator)\n        ensure_min_features = 1\n        warn_on_dtype = False\n        estimator = None\n    522     if multi_output:\n    523         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    524                         dtype=None)\n    525     else:\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array=array([], shape=(1200, 0), dtype=float64), accept_sparse=['csr'], dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    419         n_features = array.shape[1]\n    420         if n_features < ensure_min_features:\n    421             raise ValueError(\"Found array with %d feature(s) (shape=%s) while\"\n    422                              \" a minimum of %d is required%s.\"\n    423                              % (n_features, shape_repr, ensure_min_features,\n--> 424                                 context))\n        context = ''\n    425 \n    426     if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:\n    427         msg = (\"Data with input dtype %s was converted to %s%s.\"\n    428                % (dtype_orig, array.dtype, context))\n\nValueError: Found array with 0 feature(s) (shape=(1200, 0)) while a minimum of 1 is required.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 344, in __call__\n    return self.func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 238, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py\", line 270, in fit\n    self._final_estimator.fit(Xt, y, **fit_params)\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/neighbors/base.py\", line 761, in fit\n    X, y = check_X_y(X, y, \"csr\", multi_output=True)\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 521, in check_X_y\n    ensure_min_features, warn_on_dtype, estimator)\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py\", line 424, in check_array\n    context))\nValueError: Found array with 0 feature(s) (shape=(1200, 0)) while a minimum of 1 is required.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 353, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Nov 11 01:10:26 2017\nPID: 170                                Python 3.6.2: /opt/conda/bin/python\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaling', StandardScaler(copy=...ighbors=3, p=2,\n           weights='distance'))]),       28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns], 1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64, <function _passthrough_scorer>, array([ 283,  286,  287, ..., 1497, 1498, 1499]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...99, 300, 301, 307, 308, 311, 315, 316, 317, 318]), 1, {'classifier__n_neighbors': 3, 'classifier__weights': 'distance'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('scaling', StandardScaler(copy=...ighbors=3, p=2,\n           weights='distance'))]),       28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns], 1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64, <function _passthrough_scorer>, array([ 283,  286,  287, ..., 1497, 1498, 1499]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...99, 300, 301, 307, 308, 311, 315, 316, 317, 318]), 1, {'classifier__n_neighbors': 3, 'classifier__weights': 'distance'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaling', StandardScaler(copy=...ighbors=3, p=2,\n           weights='distance'))]), X=      28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns], y=1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64, scorer=<function _passthrough_scorer>, train=array([ 283,  286,  287, ..., 1497, 1498, 1499]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...99, 300, 301, 307, 308, 311, 315, 316, 317, 318]), verbose=1, parameters={'classifier__n_neighbors': 3, 'classifier__weights': 'distance'}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...ghbors=3, p=2,\n           weights='distance'))])>\n        X_train =       28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1200 rows x 20 columns]\n        y_train = 569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaling', StandardScaler(copy=...ighbors=3, p=2,\n           weights='distance'))]), X=      28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1200 rows x 20 columns], y=569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64, **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method SupervisedIntegerMixin.fit of KNei...neighbors=3, p=2,\n           weights='distance')>\n        Xt = array([], shape=(1200, 0), dtype=float64)\n        y = 569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/neighbors/base.py in fit(self=KNeighborsClassifier(algorithm='auto', leaf_size..._neighbors=3, p=2,\n           weights='distance'), X=array([], shape=(1200, 0), dtype=float64), y=569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64)\n    756         y : {array-like, sparse matrix}\n    757             Target values of shape = [n_samples] or [n_samples, n_outputs]\n    758 \n    759         \"\"\"\n    760         if not isinstance(X, (KDTree, BallTree)):\n--> 761             X, y = check_X_y(X, y, \"csr\", multi_output=True)\n        X = array([], shape=(1200, 0), dtype=float64)\n        y = 569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64\n    762 \n    763         if y.ndim == 1 or y.ndim == 2 and y.shape[1] == 1:\n    764             if y.ndim != 1:\n    765                 warnings.warn(\"A column-vector y was passed when a 1d array \"\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py in check_X_y(X=array([], shape=(1200, 0), dtype=float64), y=569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64, accept_sparse='csr', dtype='numeric', order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=True, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    516     y_converted : object\n    517         The converted and validated y.\n    518     \"\"\"\n    519     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n    520                     ensure_2d, allow_nd, ensure_min_samples,\n--> 521                     ensure_min_features, warn_on_dtype, estimator)\n        ensure_min_features = 1\n        warn_on_dtype = False\n        estimator = None\n    522     if multi_output:\n    523         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    524                         dtype=None)\n    525     else:\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array=array([], shape=(1200, 0), dtype=float64), accept_sparse=['csr'], dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    419         n_features = array.shape[1]\n    420         if n_features < ensure_min_features:\n    421             raise ValueError(\"Found array with %d feature(s) (shape=%s) while\"\n    422                              \" a minimum of %d is required%s.\"\n    423                              % (n_features, shape_repr, ensure_min_features,\n--> 424                                 context))\n        context = ''\n    425 \n    426     if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:\n    427         msg = (\"Data with input dtype %s was converted to %s%s.\"\n    428                % (dtype_orig, array.dtype, context))\n\nValueError: Found array with 0 feature(s) (shape=(1200, 0)) while a minimum of 1 is required.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Sat Nov 11 01:10:26 2017\nPID: 170                                Python 3.6.2: /opt/conda/bin/python\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaling', StandardScaler(copy=...ighbors=3, p=2,\n           weights='distance'))]),       28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns], 1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64, <function _passthrough_scorer>, array([ 283,  286,  287, ..., 1497, 1498, 1499]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...99, 300, 301, 307, 308, 311, 315, 316, 317, 318]), 1, {'classifier__n_neighbors': 3, 'classifier__weights': 'distance'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('scaling', StandardScaler(copy=...ighbors=3, p=2,\n           weights='distance'))]),       28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns], 1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64, <function _passthrough_scorer>, array([ 283,  286,  287, ..., 1497, 1498, 1499]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...99, 300, 301, 307, 308, 311, 315, 316, 317, 318]), 1, {'classifier__n_neighbors': 3, 'classifier__weights': 'distance'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaling', StandardScaler(copy=...ighbors=3, p=2,\n           weights='distance'))]), X=      28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns], y=1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64, scorer=<function _passthrough_scorer>, train=array([ 283,  286,  287, ..., 1497, 1498, 1499]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...99, 300, 301, 307, 308, 311, 315, 316, 317, 318]), verbose=1, parameters={'classifier__n_neighbors': 3, 'classifier__weights': 'distance'}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...ghbors=3, p=2,\n           weights='distance'))])>\n        X_train =       28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1200 rows x 20 columns]\n        y_train = 569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaling', StandardScaler(copy=...ighbors=3, p=2,\n           weights='distance'))]), X=      28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1200 rows x 20 columns], y=569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64, **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method SupervisedIntegerMixin.fit of KNei...neighbors=3, p=2,\n           weights='distance')>\n        Xt = array([], shape=(1200, 0), dtype=float64)\n        y = 569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/neighbors/base.py in fit(self=KNeighborsClassifier(algorithm='auto', leaf_size..._neighbors=3, p=2,\n           weights='distance'), X=array([], shape=(1200, 0), dtype=float64), y=569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64)\n    756         y : {array-like, sparse matrix}\n    757             Target values of shape = [n_samples] or [n_samples, n_outputs]\n    758 \n    759         \"\"\"\n    760         if not isinstance(X, (KDTree, BallTree)):\n--> 761             X, y = check_X_y(X, y, \"csr\", multi_output=True)\n        X = array([], shape=(1200, 0), dtype=float64)\n        y = 569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64\n    762 \n    763         if y.ndim == 1 or y.ndim == 2 and y.shape[1] == 1:\n    764             if y.ndim != 1:\n    765                 warnings.warn(\"A column-vector y was passed when a 1d array \"\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py in check_X_y(X=array([], shape=(1200, 0), dtype=float64), y=569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64, accept_sparse='csr', dtype='numeric', order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=True, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    516     y_converted : object\n    517         The converted and validated y.\n    518     \"\"\"\n    519     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n    520                     ensure_2d, allow_nd, ensure_min_samples,\n--> 521                     ensure_min_features, warn_on_dtype, estimator)\n        ensure_min_features = 1\n        warn_on_dtype = False\n        estimator = None\n    522     if multi_output:\n    523         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    524                         dtype=None)\n    525     else:\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array=array([], shape=(1200, 0), dtype=float64), accept_sparse=['csr'], dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    419         n_features = array.shape[1]\n    420         if n_features < ensure_min_features:\n    421             raise ValueError(\"Found array with %d feature(s) (shape=%s) while\"\n    422                              \" a minimum of %d is required%s.\"\n    423                              % (n_features, shape_repr, ensure_min_features,\n--> 424                                 context))\n        context = ''\n    425 \n    426     if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:\n    427         msg = (\"Data with input dtype %s was converted to %s%s.\"\n    428                % (dtype_orig, array.dtype, context))\n\nValueError: Found array with 0 feature(s) (shape=(1200, 0)) while a minimum of 1 is required.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-83908fb7087f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msample_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mUCIfull_clean\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscore_pipelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_zip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-d78be5dfc6fc>\u001b[0m in \u001b[0;36mscore_pipelines\u001b[0;34m(sample_list, model_zip)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_zip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0mtrain\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m         \"\"\"\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    562\u001b[0m                                   \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m--> 564\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m           for train, test in cv_iter)\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/opt/conda/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/opt/conda/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f79def11ed0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/opt/conda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f79def11ed0, file \"/...3.6/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/opt/conda/lib/python3.6/site-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/site-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 11, 1, 10, 26, 734374, tzinfo=tzlocal()), 'msg_id': 'A0341C46063B4393B8F8B29085A5CB59', 'msg_type': 'execute_request', 'session': 'B7857C7A06174F88859E10F31B92B67D', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'A0341C46063B4393B8F8B29085A5CB59', 'msg_type': 'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'B7857C7A06174F88859E10F31B92B67D']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 11, 1, 10, 26, 734374, tzinfo=tzlocal()), 'msg_id': 'A0341C46063B4393B8F8B29085A5CB59', 'msg_type': 'execute_request', 'session': 'B7857C7A06174F88859E10F31B92B67D', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'A0341C46063B4393B8F8B29085A5CB59', 'msg_type': 'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'B7857C7A06174F88859E10F31B92B67D'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 11, 11, 1, 10, 26, 734374, tzinfo=tzlocal()), 'msg_id': 'A0341C46063B4393B8F8B29085A5CB59', 'msg_type': 'execute_request', 'session': 'B7857C7A06174F88859E10F31B92B67D', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'A0341C46063B4393B8F8B29085A5CB59', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\", store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-9-83908fb7087f>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f79a0993898, executi..._before_exec=None error_in_exec=None result=None>)\n   2845 \n   2846         try:\n   2847             for i, node in enumerate(to_run_exec):\n   2848                 mod = ast.Module([node])\n   2849                 code = compiler(mod, cell_name, \"exec\")\n-> 2850                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f79a0ae6ae0, file \"<ipython-input-9-83908fb7087f>\", line 2>\n        result = <ExecutionResult object at 7f79a0993898, executi..._before_exec=None error_in_exec=None result=None>\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f79a0ae6ae0, file \"<ipython-input-9-83908fb7087f>\", line 2>, result=<ExecutionResult object at 7f79a0993898, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f79a0ae6ae0, file \"<ipython-input-9-83908fb7087f>\", line 2>\n        self.user_global_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'DBfull_clean':         feat_257  feat_269  feat_308  feat_315  ...0 -0.559682       1  \n\n[200000 rows x 21 columns], 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport numpy as np\\nimport se...ictCursor\\nfrom sklearn.linear_model import Linear', 'import pandas as pd\\nimport numpy as np\\nimport se...DictCursor\\nfrom sklearn.linear_model import Lasso', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', 'import pandas as pd\\nimport numpy as np\\nimport se... sklearn.feature_selection import SelectFromModel', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', \"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\"], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, ...}\n        self.user_ns = {'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'BaggingClassifier': <class 'sklearn.ensemble.bagging.BaggingClassifier'>, 'DBfull_clean':         feat_257  feat_269  feat_308  feat_315  ...0 -0.559682       1  \n\n[200000 rows x 21 columns], 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'ExtraTreesClassifier': <class 'sklearn.ensemble.forest.ExtraTreesClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import pandas as pd\\nimport numpy as np\\nimport se...ictCursor\\nfrom sklearn.linear_model import Linear', 'import pandas as pd\\nimport numpy as np\\nimport se...DictCursor\\nfrom sklearn.linear_model import Lasso', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', 'import pandas as pd\\nimport numpy as np\\nimport se... sklearn.feature_selection import SelectFromModel', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', '# define my controlling function and pipelines t..._gs]\\nmodel_zip = list(zip(pipe_names, pipe_list))', \"sample_list = [UCIfull_clean]\\nresults = score_pi...ts.sort_values('test_accuracy', ascending=False))\"], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'Lasso': <class 'sklearn.linear_model.coordinate_descent.Lasso'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/jovyan/work/project_3/<ipython-input-9-83908fb7087f> in <module>()\n      1 \n----> 2 \n      3 \n      4 \n      5 sample_list = [UCIfull_clean]\n      6 results = score_pipelines(sample_list, model_zip)\n      7 display(results.sort_values('test_accuracy', ascending=False))\n      8 \n      9 \n     10 \n\n...........................................................................\n/home/jovyan/work/project_3/<ipython-input-8-d78be5dfc6fc> in score_pipelines(sample_list=[      28   48   64   105  128  153  241  281  31...2  487  560  449    1  \n\n[2000 rows x 21 columns]], model_zip=[('knn_gs', GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1)), ('svc_gs', GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1)), ('bag_gs', GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1)), ('rfc_gs', GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1)), ('etc_gs', GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1))])\n      8     for sample in sample_list:\n      9         y = sample.iloc[:,-1]\n     10         X = sample.iloc[:,0:-1]\n     11         X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size=0.25, stratify=y)\n     12         for model_name, model in tqdm(model_zip):\n---> 13             model.fit(X_train, y_train)\n     14             y_pred = model.predict(X_test)\n     15             recall = recall_score(y_test, y_pred)\n     16             precision = precision_score(y_test, y_pred)\n     17             results.append({\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1), X=      28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns], y=1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64, groups=None)\n    940 \n    941         groups : array-like, with shape (n_samples,), optional\n    942             Group labels for the samples used while splitting the dataset into\n    943             train/test set.\n    944         \"\"\"\n--> 945         return self._fit(X, y, groups, ParameterGrid(self.param_grid))\n        self._fit = <bound method BaseSearchCV._fit of GridSearchCV(...rain_score=True,\n       scoring=None, verbose=1)>\n        X =       28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns]\n        y = 1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64\n        groups = None\n        self.param_grid = {'classifier__n_neighbors': array([ 3,  5,  7,  9, 11]), 'classifier__weights': ['distance']}\n    946 \n    947 \n    948 class RandomizedSearchCV(BaseSearchCV):\n    949     \"\"\"Randomized search on hyper parameters.\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_search.py in _fit(self=GridSearchCV(cv=5, error_score='raise',\n       e...train_score=True,\n       scoring=None, verbose=1), X=      28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns], y=1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64, groups=None, parameter_iterable=<sklearn.model_selection._search.ParameterGrid object>)\n    559                                   fit_params=self.fit_params,\n    560                                   return_train_score=self.return_train_score,\n    561                                   return_n_test_samples=True,\n    562                                   return_times=True, return_parameters=True,\n    563                                   error_score=self.error_score)\n--> 564           for parameters in parameter_iterable\n        parameters = undefined\n        parameter_iterable = <sklearn.model_selection._search.ParameterGrid object>\n    565           for train, test in cv_iter)\n    566 \n    567         # if one choose to see train score, \"out\" will contain train score info\n    568         if self.return_train_score:\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV._fit.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sat Nov 11 01:10:26 2017\nPID: 170                                Python 3.6.2: /opt/conda/bin/python\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(steps=[('scaling', StandardScaler(copy=...ighbors=3, p=2,\n           weights='distance'))]),       28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns], 1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64, <function _passthrough_scorer>, array([ 283,  286,  287, ..., 1497, 1498, 1499]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...99, 300, 301, 307, 308, 311, 315, 316, 317, 318]), 1, {'classifier__n_neighbors': 3, 'classifier__weights': 'distance'}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(steps=[('scaling', StandardScaler(copy=...ighbors=3, p=2,\n           weights='distance'))]),       28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns], 1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64, <function _passthrough_scorer>, array([ 283,  286,  287, ..., 1497, 1498, 1499]), array([  0,   1,   2,   3,   4,   5,   6,   7,  ...99, 300, 301, 307, 308, 311, 315, 316, 317, 318]), 1, {'classifier__n_neighbors': 3, 'classifier__weights': 'distance'})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': True, 'return_times': True, 'return_train_score': True}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=Pipeline(steps=[('scaling', StandardScaler(copy=...ighbors=3, p=2,\n           weights='distance'))]), X=      28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1500 rows x 20 columns], y=1082   -1\n1771   -1\n164     1\n23      1\n506    -...    1\n578     1\n1067    1\nName: 500, dtype: int64, scorer=<function _passthrough_scorer>, train=array([ 283,  286,  287, ..., 1497, 1498, 1499]), test=array([  0,   1,   2,   3,   4,   5,   6,   7,  ...99, 300, 301, 307, 308, 311, 315, 316, 317, 318]), verbose=1, parameters={'classifier__n_neighbors': 3, 'classifier__weights': 'distance'}, fit_params={}, return_train_score=True, return_parameters=True, return_n_test_samples=True, return_times=True, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method Pipeline.fit of Pipeline(steps=[('...ghbors=3, p=2,\n           weights='distance'))])>\n        X_train =       28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1200 rows x 20 columns]\n        y_train = 569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/pipeline.py in fit(self=Pipeline(steps=[('scaling', StandardScaler(copy=...ighbors=3, p=2,\n           weights='distance'))]), X=      28   48   64   105  128  153  241  281  31...7  452  503  537  612  \n\n[1200 rows x 20 columns], y=569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64, **fit_params={})\n    265         self : Pipeline\n    266             This estimator\n    267         \"\"\"\n    268         Xt, fit_params = self._fit(X, y, **fit_params)\n    269         if self._final_estimator is not None:\n--> 270             self._final_estimator.fit(Xt, y, **fit_params)\n        self._final_estimator.fit = <bound method SupervisedIntegerMixin.fit of KNei...neighbors=3, p=2,\n           weights='distance')>\n        Xt = array([], shape=(1200, 0), dtype=float64)\n        y = 569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64\n        fit_params = {}\n    271         return self\n    272 \n    273     def fit_transform(self, X, y=None, **fit_params):\n    274         \"\"\"Fit the model and transform with the final estimator\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/neighbors/base.py in fit(self=KNeighborsClassifier(algorithm='auto', leaf_size..._neighbors=3, p=2,\n           weights='distance'), X=array([], shape=(1200, 0), dtype=float64), y=569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64)\n    756         y : {array-like, sparse matrix}\n    757             Target values of shape = [n_samples] or [n_samples, n_outputs]\n    758 \n    759         \"\"\"\n    760         if not isinstance(X, (KDTree, BallTree)):\n--> 761             X, y = check_X_y(X, y, \"csr\", multi_output=True)\n        X = array([], shape=(1200, 0), dtype=float64)\n        y = 569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64\n    762 \n    763         if y.ndim == 1 or y.ndim == 2 and y.shape[1] == 1:\n    764             if y.ndim != 1:\n    765                 warnings.warn(\"A column-vector y was passed when a 1d array \"\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py in check_X_y(X=array([], shape=(1200, 0), dtype=float64), y=569    -1\n13     -1\n1654   -1\n1218   -1\n1890   -...    1\n578     1\n1067    1\nName: 500, dtype: int64, accept_sparse='csr', dtype='numeric', order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, multi_output=True, ensure_min_samples=1, ensure_min_features=1, y_numeric=False, warn_on_dtype=False, estimator=None)\n    516     y_converted : object\n    517         The converted and validated y.\n    518     \"\"\"\n    519     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n    520                     ensure_2d, allow_nd, ensure_min_samples,\n--> 521                     ensure_min_features, warn_on_dtype, estimator)\n        ensure_min_features = 1\n        warn_on_dtype = False\n        estimator = None\n    522     if multi_output:\n    523         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n    524                         dtype=None)\n    525     else:\n\n...........................................................................\n/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py in check_array(array=array([], shape=(1200, 0), dtype=float64), accept_sparse=['csr'], dtype=None, order=None, copy=False, force_all_finite=True, ensure_2d=True, allow_nd=False, ensure_min_samples=1, ensure_min_features=1, warn_on_dtype=False, estimator=None)\n    419         n_features = array.shape[1]\n    420         if n_features < ensure_min_features:\n    421             raise ValueError(\"Found array with %d feature(s) (shape=%s) while\"\n    422                              \" a minimum of %d is required%s.\"\n    423                              % (n_features, shape_repr, ensure_min_features,\n--> 424                                 context))\n        context = ''\n    425 \n    426     if warn_on_dtype and dtype_orig is not None and array.dtype != dtype_orig:\n    427         msg = (\"Data with input dtype %s was converted to %s%s.\"\n    428                % (dtype_orig, array.dtype, context))\n\nValueError: Found array with 0 feature(s) (shape=(1200, 0)) while a minimum of 1 is required.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "sample_list = [UCIfull_clean]\n",
    "results = score_pipelines(sample_list, model_zip)\n",
    "display(results.sort_values('test_accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    display(results.best_params.iloc[i])\n",
    "    \n",
    "# using some of these lessons, modify for the full DB run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting the parameters based on which ones crash AWS and which don't...\n",
    "\n",
    "knn_params = {\n",
    "              'classifier__weights':['distance'],\n",
    "              'classifier__n_neighbors':np.arange(5,11,2)}\n",
    "\n",
    "svc_params = {\n",
    "               'classifier__gamma':np.logspace(-2,2,3), \n",
    "               'classifier__C':np.logspace(-2,2,3),\n",
    "               'classifier__kernel':['rbf']}\n",
    "\n",
    "rfc_params = {\n",
    "                'clf__n_estimators':[100],\n",
    "                'clf__max_features':['auto']}\n",
    "\n",
    "svc_gs = GridSearchCV(svc, svc_params, cv=3, n_jobs=-1, verbose=10)\n",
    "knn_gs = GridSearchCV(knn, knn_params, cv=3, n_jobs=-1, verbose=10)\n",
    "rfc_gs = GridSearchCV(rfc, rfc_params, cv=3, n_jobs=-1, verbose=10)\n",
    "\n",
    "pipe_names = ['svc_gs', 'knn_gs', 'rfc_gs']\n",
    "pipe_list = [svc_gs, knn_gs, rfc_gs]\n",
    "model_zip = list(zip(pipe_names, pipe_list))\n",
    "\n",
    "sample_list = [DBfull_clean]\n",
    "results = score_pipelines(sample_list, model_zip)\n",
    "display(results.sort_values('test_accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,1):\n",
    "    display(results.best_params.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# etc_params = {\n",
    "# #     'clf__bootstrap':[True, False],\n",
    "#     'clf__n_estimators':[100,200]}\n",
    "\n",
    "rfc_params = {\n",
    "    'clf__n_estimators':[100,200],\n",
    "    'clf__max_features':['auto']}\n",
    "\n",
    "# etc_gs = GridSearchCV(etc, etc_params, cv=3, n_jobs=-1, verbose=10)\n",
    "rfc_gs = GridSearchCV(rfc, rfc_params, cv=3, n_jobs=-1, verbose=10)\n",
    "\n",
    "pipe_names = ['rfc_gs']\n",
    "pipe_list = [rfc_gs]\n",
    "model_zip = list(zip(pipe_names, pipe_list))\n",
    "\n",
    "sample_list = [DBfull_clean]\n",
    "results = score_pipelines(sample_list, model_zip)\n",
    "display(results.sort_values('test_accuracy', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
